{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflection Workflow for Structured Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import RagaAI Catalyst components for tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token(s) set successfully\n"
     ]
    }
   ],
   "source": [
    "from ragaai_catalyst.tracers import Tracer\n",
    "from ragaai_catalyst import RagaAICatalyst, init_tracing\n",
    "import os\n",
    "\n",
    "catalyst = RagaAICatalyst(\n",
    "    access_key=os.getenv(\"RAGAAI_CATALYST_ACCESS_KEY\"),\n",
    "    secret_key=os.getenv(\"RAGAAI_CATALYST_SECRET_KEY\"),\n",
    "    base_url=os.getenv(\"RAGAAI_CATALYST_BASE_URL\"),\n",
    ")\n",
    "\n",
    "# Initialize tracer\n",
    "tracer = Tracer(\n",
    "    project_name=\"llamaindex_tracing_examples\",\n",
    "    dataset_name=\"reflection\",\n",
    "    tracer_type=\"Agentic\",\n",
    ")\n",
    "\n",
    "init_tracing(catalyst=catalyst, tracer=tracer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import Event\n",
    "\n",
    "\n",
    "class ExtractionDone(Event):\n",
    "    output: str\n",
    "    passage: str\n",
    "\n",
    "\n",
    "class ValidationErrorEvent(Event):\n",
    "    error: str\n",
    "    wrong_output: str\n",
    "    passage: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Car(BaseModel):\n",
    "    brand: str\n",
    "    model: str\n",
    "    power: int\n",
    "\n",
    "\n",
    "class CarCollection(BaseModel):\n",
    "    cars: list[Car]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from llama_index.core.workflow import (\n",
    "    Workflow,\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Context,\n",
    "    step,\n",
    ")\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "EXTRACTION_PROMPT = \"\"\"\n",
    "Context information is below:\n",
    "---------------------\n",
    "{passage}\n",
    "---------------------\n",
    "\n",
    "Given the context information and not prior knowledge, create a JSON object from the information in the context.\n",
    "The JSON object must follow the JSON schema:\n",
    "{schema}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "REFLECTION_PROMPT = \"\"\"\n",
    "You already created this output previously:\n",
    "---------------------\n",
    "{wrong_answer}\n",
    "---------------------\n",
    "\n",
    "This caused the JSON decode error: {error}\n",
    "\n",
    "Try again, the response must contain only valid JSON code. Do not add any sentence before or after the JSON object.\n",
    "Do not repeat the schema.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class ReflectionWorkflow(Workflow):\n",
    "    max_retries: int = 3\n",
    "\n",
    "    @step\n",
    "    async def extract(\n",
    "        self, ctx: Context, ev: StartEvent | ValidationErrorEvent\n",
    "    ) -> StopEvent | ExtractionDone:\n",
    "        current_retries = await ctx.get(\"retries\", default=0)\n",
    "        if current_retries >= self.max_retries:\n",
    "            return StopEvent(result=\"Max retries reached\")\n",
    "        else:\n",
    "            await ctx.set(\"retries\", current_retries + 1)\n",
    "\n",
    "        if isinstance(ev, StartEvent):\n",
    "            passage = ev.get(\"passage\")\n",
    "            if not passage:\n",
    "                return StopEvent(result=\"Please provide some text in input\")\n",
    "            reflection_prompt = \"\"\n",
    "        elif isinstance(ev, ValidationErrorEvent):\n",
    "            passage = ev.passage\n",
    "            reflection_prompt = REFLECTION_PROMPT.format(\n",
    "                wrong_answer=ev.wrong_output, error=ev.error\n",
    "            )\n",
    "\n",
    "        llm = OpenAI(model=\"gpt-4o-mini\", request_timeout=30)\n",
    "        prompt = EXTRACTION_PROMPT.format(\n",
    "            passage=passage, schema=CarCollection.schema_json()\n",
    "        )\n",
    "        if reflection_prompt:\n",
    "            prompt += reflection_prompt\n",
    "\n",
    "        output = await llm.acomplete(prompt)\n",
    "\n",
    "        return ExtractionDone(output=str(output), passage=passage)\n",
    "\n",
    "    @step\n",
    "    async def validate(\n",
    "        self, ev: ExtractionDone\n",
    "    ) -> StopEvent | ValidationErrorEvent:\n",
    "        try:\n",
    "            CarCollection.model_validate_json(ev.output)\n",
    "        except Exception as e:\n",
    "            print(\"Validation failed, retrying...\")\n",
    "            return ValidationErrorEvent(\n",
    "                error=str(e), wrong_output=ev.output, passage=ev.passage\n",
    "            )\n",
    "\n",
    "        return StopEvent(result=ev.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = ReflectionWorkflow(timeout=120, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the workflow with RagaAI Catalyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Failed to patch Anthropic methods: ChatAnthropic.invoke\n",
      "Running step extract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parte\\AppData\\Local\\Temp\\ipykernel_15980\\1242926840.py:63: PydanticDeprecatedSince20: The `schema_json` method is deprecated; use `model_json_schema` and json.dumps instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  passage=passage, schema=CarCollection.schema_json()\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step extract produced event ExtractionDone\n",
      "Running step validate\n",
      "Validation failed, retrying...\n",
      "Step validate produced event ValidationErrorEvent\n",
      "Running step extract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:ragaai_catalyst.tracers.agentic_tracing.utils.zip_list_of_unique_files: Zip file created successfully.\n",
      "INFO:ragaai_catalyst.tracers.agentic_tracing.tracers.base: Traces saved successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step extract produced event ExtractionDone\n",
      "Running step validate\n",
      "Step validate produced event StopEvent\n",
      "Uploading agentic traces...\n",
      "Uploading code...\n",
      "Dataset trace code inserted successfully\n"
     ]
    }
   ],
   "source": [
    "with tracer:\n",
    "    ret = await w.run(\n",
    "        passage=\"I own two cars: a Fiat Panda with 45Hp and a Honda Civic with 330Hp.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"cars\": [\n",
      "    {\n",
      "      \"brand\": \"Fiat\",\n",
      "      \"model\": \"Panda\",\n",
      "      \"power\": 45\n",
      "    },\n",
      "    {\n",
      "      \"brand\": \"Honda\",\n",
      "      \"model\": \"Civic\",\n",
      "      \"power\": 330\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(ret)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
